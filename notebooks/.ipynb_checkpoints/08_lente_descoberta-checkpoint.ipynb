{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a174ca-3c33-43ac-a0ef-b62ce0e24fd2",
   "metadata": {},
   "source": [
    "# 8 · A Ótica Adequada: Por Que a Escala Logarítmica É Estrutural\n",
    "\n",
    "**Registro observacional associado ao livro**  \n",
    "*Descobrindo o Caos nos Números Primos — Investigações Computacionais sob o Espelho de Euler*  \n",
    "© Alvaro Costa, 2025  \n",
    "\n",
    "Este notebook faz parte de uma sequência canônica de registros computacionais. Ele não introduz hipóteses, conjecturas ou modelos interpretativos novos.\n",
    "\n",
    "Seu objetivo é exclusivamente **registrar** o comportamento de estruturas aritméticas sob um regime de observação explícito, determinístico e reproduzível.\n",
    "\n",
    "A leitura conceitual completa encontra-se no livro. Este notebook documenta apenas o experimento correspondente.\n",
    "\n",
    "**Licença:** Creative Commons BY–NC–ND 4.0  \n",
    "É permitida a leitura, execução e citação. Não é permitida a modificação, redistribuição adaptada ou uso comercial independente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606782c-3cd5-4ec6-a1d6-70e690b7e33c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Distintos regimes estatísticos sob diferentes métricas de observação\n",
    "\n",
    "Nos capítulos anteriores, foi observada a emergência de estatísticas compatíveis com a GOE a partir do operador $M$. Uma análise adicional revela, no entanto, um ponto crucial: **o regime estatístico observado depende da métrica de amostragem adotada na reta numérica**.\n",
    "\n",
    "Quando os pontos $x_i$ são amostrados de forma **linear**, o espectro de $M$ apresenta estatísticas compatíveis com um regime **Poisson**. Quando a amostragem é feita de forma **logarítmica**, mantendo fixa a construção do operador e a região aritmética analisada, emerge claramente um regime **correlacionado**, compatível com a estatística **GOE**.\n",
    "\n",
    "Este contraste não é um artefato numérico. Ele reflete a dependência explícita entre o operador construído e a métrica de observação utilizada.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Métrica de observação e escala natural dos primos\n",
    "\n",
    "A densidade assintótica dos números primos é governada pela relação\n",
    "$$\n",
    "\\pi(x) \\sim \\frac{x}{\\ln x},\n",
    "$$\n",
    "o que indica que a escala natural associada à distribuição dos primos é **logarítmica**, e não linear.\n",
    "\n",
    "Consequentemente, a escolha da métrica de amostragem atua como um filtro estrutural:  \n",
    "- métricas compatíveis com a escala logarítmica preservam as variações relevantes do sinal aritmético;\n",
    "- métricas incompatíveis tendem a suprimir correlações de longo alcance.\n",
    "\n",
    "Assim, diferentes estratégias de amostragem correspondem a diferentes regimes de observação do *mesmo* operador.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Amostragem logarítmica e regime correlacionado\n",
    "\n",
    "Quando os pontos $x_i$ são distribuídos uniformemente em $\\ln x$, a amostragem permanece coerente com a estrutura multiplicativa implícita no operador $M$.\n",
    "\n",
    "- **Efeito sobre $\\Delta_\\pi(x)$:**  \n",
    "  As flutuações do sinal são amostradas de forma equilibrada ao longo da escala, preservando sua variabilidade estrutural.\n",
    "\n",
    "- **Consequência espectral:**  \n",
    "  A matriz $M$ resultante apresenta alta complexidade interna, e o espectro exibe repulsão de níveis característica de estatísticas correlacionadas, compatíveis com a classe **GOE (Gaussian Orthogonal Ensemble)**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Amostragem linear e regime não correlacionado\n",
    "\n",
    "Quando os pontos $x_i$ são distribuídos uniformemente em $x$, a amostragem ignora a escala logarítmica subjacente à distribuição dos primos.\n",
    "\n",
    "- **Efeito sobre $\\Delta_\\pi(x)$:**  \n",
    "  Em janelas lineares restritas, o sinal varia lentamente e apresenta flutuações aproximadamente independentes.\n",
    "\n",
    "- **Consequência espectral:**  \n",
    "  A matriz $M$ construída nesse regime possui menor variabilidade efetiva, e o espectro resultante é compatível com estatísticas de eventos independentes, isto é, um regime **Poisson**.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Comparação entre regimes de observação\n",
    "\n",
    "| Característica | Amostragem Linear | Amostragem Logarítmica |\n",
    "|---------------|------------------|------------------------|\n",
    "| Métrica de amostragem | Linear em $x$ | Uniforme em $\\ln x$ |\n",
    "| Compatibilidade com $\\pi(x)$ | Baixa | Alta |\n",
    "| Variabilidade de $\\Delta_\\pi(x)$ | Localmente reduzida | Estruturalmente preservada |\n",
    "| Complexidade do operador $M$ | Baixa | Elevada |\n",
    "| Estatística espectral | Poisson | GOE |\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Normalização local e verificação do regime Poisson\n",
    "\n",
    "No regime linear, pequenas variações residuais da densidade espectral podem obscurecer a identificação do comportamento Poisson.\n",
    "\n",
    "A função `local_normalize_spacings` aplica uma normalização local dos espaçamentos espectrais, compensando variações suaves da densidade média.\n",
    "\n",
    "Este procedimento:\n",
    "- **não introduz correlação**;\n",
    "- **não altera o operador**;\n",
    "- apenas remove efeitos de escala que poderiam mascarar o regime estatístico subjacente.\n",
    "\n",
    "Após essa normalização, a distribuição Poisson emerge de forma nítida, confirmando que se trata de uma **propriedade observacional do sistema sob esta métrica**, e não de um artefato computacional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ffb1ff-3612-4673-87ce-34aa35804781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d45b620476743f0ab652bbcc896e769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='N:', index=2, options=(512, 1024, 2048), value=2048), IntSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Requisitos: pandas, matplotlib, numpy, ipywidgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import time\n",
    "\n",
    "# --- Funções de Geração de Dados e Matriz ---\n",
    "def generate_pi_data(n: int) -> np.ndarray:\n",
    "    \"\"\"Gera um array com todos os primos até n usando um crivo otimizado.\"\"\"\n",
    "    if n < 2: return np.array([], dtype=np.int64)\n",
    "    size = (n - 1) // 2; sieve = np.ones(size, dtype=bool)\n",
    "    limit = int(np.sqrt(n)) // 2\n",
    "    for i in range(limit):\n",
    "        if sieve[i]:\n",
    "            p = 2 * i + 3; start = (p*p - 3) // 2\n",
    "            sieve[start::p] = False\n",
    "    indices = np.where(sieve)[0]; odd_primes = 2 * indices + 3\n",
    "    return np.concatenate((np.array([2], dtype=np.int64), odd_primes))\n",
    "\n",
    "def get_delta_pi_for_points(x_points, primes):\n",
    "    \"\"\"Calcula Δπ(x) para um array de pontos x usando uma lista de primos pré-calculada.\"\"\"\n",
    "    x_int = np.floor(x_points).astype(int)\n",
    "    pi_x = np.searchsorted(primes, x_int, side='right')\n",
    "    pi_x_div_2 = np.searchsorted(primes, x_int // 2, side='right')\n",
    "    return pi_x - 2 * pi_x_div_2\n",
    "    \n",
    "def generate_cos_matrix(fx_values, x_values):\n",
    "    \"\"\"Gera a matriz M a partir dos vetores F(x) e x.\"\"\"\n",
    "    fx = fx_values.astype(np.float64); x = x_values.astype(np.float64)\n",
    "    x[x <= 0] = 1e-12; logx = np.log(x)\n",
    "    C = np.cos(np.outer(fx, logx)); M = C + C.T\n",
    "    std_dev = M.std()\n",
    "    if std_dev > 0:\n",
    "        M -= M.mean()\n",
    "        M /= std_dev\n",
    "    return 0.5 * (M + M.T)\n",
    "\n",
    "# bulk fixo em 90% central (alpha = 0.10)\n",
    "# janela local fixa para unfolding (não otimizada) w = 21\n",
    "def local_normalize_spacings(lam, alpha=0.10, w=21):\n",
    "    \"\"\"\n",
    "    Normaliza os espaçamentos pela sua média local (unfolding).\n",
    "    Esta é a chave para visualizar corretamente a estatística de Poisson.\n",
    "    \"\"\"\n",
    "    N = lam.size\n",
    "    # Pega o \"bulk\" (meio) do espectro para evitar efeitos de borda\n",
    "    k0, k1 = int(alpha * N), int((1 - alpha) * N)\n",
    "    lam_bulk = np.sort(lam)[k0:k1]\n",
    "    \n",
    "    s = np.diff(lam_bulk)\n",
    "    s = s[s > 0]\n",
    "    \n",
    "    if len(s) < w: return s / s.mean() if s.mean() > 0 else s\n",
    "\n",
    "    # Usa uma média móvel para encontrar a densidade local de estados\n",
    "    w = int(w)\n",
    "    if w % 2 == 0: w += 1 # A janela deve ser ímpar\n",
    "    pad = w // 2\n",
    "    s_padded = np.pad(s, (pad, pad), mode='reflect')\n",
    "    local_mean = np.convolve(s_padded, np.ones(w)/w, mode='valid')\n",
    "    \n",
    "    # Evita divisão por zero\n",
    "    local_mean[local_mean == 0] = 1.0\n",
    "    \n",
    "    return s / local_mean\n",
    "\n",
    "# --- A Função Interativa Principal ---\n",
    "def scale_comparison_lab(N=2048, log_X0=8, span=2.4):\n",
    "    \n",
    "    X0 = int(10**log_X0)\n",
    "    \n",
    "    # --- Preparação dos Dados ---\n",
    "    max_x_log = int(np.ceil(X0 * np.exp(span/2)))\n",
    "    max_x_linear = X0 + N\n",
    "    max_x_needed = max(max_x_log, max_x_linear)\n",
    "    pi_x_full = generate_pi_data(max_x_needed)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True) \n",
    "    \n",
    "    # --- Gráfico da Esquerda: Amostragem Linear (Poisson) ---\n",
    "    print(\"\\n--- Processando Escala Linear ---\")\n",
    "    x_linear = np.arange(X0, X0 + N)\n",
    "    fx_linear = get_delta_pi_for_points(x_linear, pi_x_full)\n",
    "    \n",
    "    M_linear = generate_cos_matrix(fx_linear, x_linear)\n",
    "    lam_linear, _ = np.linalg.eigh(M_linear)\n",
    "    # USA A NORMALIZAÇÃO LOCAL PARA OBTER POISSON\n",
    "    s_unfolded_linear = local_normalize_spacings(lam_linear)\n",
    "\n",
    "    # --- Gráfico da Direita: Amostragem Logarítmica (GOE) ---\n",
    "    print(\"\\n--- Processando Escala Logarítmica ---\")\n",
    "    x_log = np.exp(np.linspace(np.log(X0) - span/2, np.log(X0) + span/2, N))\n",
    "    fx_log = get_delta_pi_for_points(x_log, pi_x_full)\n",
    "\n",
    "    M_log = generate_cos_matrix(fx_log, x_log)\n",
    "    lam_log, _ = np.linalg.eigh(M_log)\n",
    "    # Para GOE, a normalização pela média global já funciona bem\n",
    "    s_log = np.diff(np.sort(lam_log)); s_log = s_log[s_log > 0]\n",
    "    s_unfolded_log = s_log / s_log.mean()\n",
    "\n",
    "    # --- Plots Comparativos ---\n",
    "    s_grid = np.linspace(0, 4, 200)\n",
    "    pdf_goe = (np.pi * s_grid / 2) * np.exp(-np.pi * s_grid**2 / 4)\n",
    "    pdf_poisson = np.exp(-s_grid)\n",
    "    \n",
    "    # Plot da Esquerda\n",
    "    ax = axes[0]\n",
    "    ax.hist(s_unfolded_linear, bins='auto', density=True, alpha=0.75, label='Dados (Linear)')\n",
    "    ax.plot(s_grid, pdf_goe, 'r--', lw=2, label='Teoria GOE')\n",
    "    ax.plot(s_grid, pdf_poisson, 'g:', lw=3, label='Teoria Poisson')\n",
    "    ax.set_title(f'a) Escala Linear → Regime Não Correlacionado', fontsize=14)\n",
    "    ax.set_xlabel('s (Espaçamento Normalizado Localmente)'); ax.set_ylabel('Densidade')\n",
    "    ax.set_xlim(0, 4); ax.legend(loc='upper right')\n",
    "    \n",
    "    # Plot da Direita\n",
    "    ax = axes[1]\n",
    "    ax.hist(s_unfolded_log, bins='auto', density=True, alpha=0.75, label='Dados (Log)')\n",
    "    ax.plot(s_grid, pdf_goe, 'r--', lw=2, label='Teoria GOE')\n",
    "    ax.plot(s_grid, pdf_poisson, 'g:', lw=3, label='Teoria Poisson')\n",
    "    ax.set_title(f'b) Escala Logarítmica → Regime Correlacionado', fontsize=14)\n",
    "    ax.set_xlabel('s (Espaçamento Normalizado Globalmente)'); ax.legend(loc='upper right')\n",
    "    ax.set_xlim(0, 4)\n",
    "    \n",
    "    fig.suptitle(f\"Comparação Visual do Efeito da Escala em X₀ = {X0:g}\", fontsize=18, weight='bold')\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# --- Widget Interativo ---\n",
    "interact(scale_comparison_lab, \n",
    "         N=widgets.Dropdown(options=[512, 1024, 2048], value=2048, description='N:'),\n",
    "         log_X0=widgets.IntSlider(min=5, max=8, step=1, value=8, description='X₀=10^', continuous_update=False),\n",
    "         span=widgets.FloatSlider(min=1.0, max=4.0, step=0.1, value=2.4, description='Span (Log):')\n",
    "        );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a0b824-0d91-4315-9831-eb9816d89dc6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Observação final\n",
    "\n",
    "O contraste entre estatísticas Poisson e GOE não indica a presença de dois sistemas distintos, mas reflete a dependência da estatística espectral em relação à **adequação entre o operador e a métrica de observação**.\n",
    "\n",
    "No próximo notebook, será analisada de forma mais detalhada a estrutura matemática que torna a amostragem logarítmica não apenas conveniente, mas necessária para a observação de correlações espectrais de longo alcance neste operador.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
